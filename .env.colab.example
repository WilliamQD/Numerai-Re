# =============================================================
# Numerai-Re Colab runtime config (COPY to .env.colab and edit)
# =============================================================
# How to use:
#   1) cp .env.colab.example .env.colab
#   2) Fill secrets + tune values in .env.colab
#   3) Put .env.colab at /content/drive/MyDrive/Numerai-Re/.env.colab
#   4) In Colab notebook, run setup cells; Drive env is auto-loaded first
#
# Security:
# - Keep .env.colab private (DO NOT commit)
# - .env is already gitignored in this repo; .env.colab is also gitignored below

# Drive path used by notebook env loader. Usually do not change.
COLAB_ENV_PATH=/content/drive/MyDrive/Numerai-Re/.env.colab

# -----------------------------
# Required secret
# -----------------------------
# REQUIRED for training. You can also keep this in Colab Secrets instead.
WANDB_API_KEY=

# -----------------------------
# Data / IO (strongly recommended)
# -----------------------------
# Train from local Colab disk for speed/stability.
NUMERAI_DATA_DIR=/content/numerai_data

# Persistent Drive cache source (copied to local NUMERAI_DATA_DIR each session when enabled).
COLAB_DRIVE_DATA_ROOT=/content/drive/MyDrive/Numerai-Re/datasets/numerai

# Enable Drive-cache -> local sync in notebook setup (recommended).
COLAB_SYNC_DATA_FROM_DRIVE=true

# in_memory: always read/convert parquet each run
# cached: writes/uses _np_cache arrays for much faster reruns
# Recommended: cached
LOAD_MODE=cached

# Only 'polars' is used today; keep as default.
LOAD_BACKEND=polars

# Status refresh cadence (seconds). Lower = more frequent updates.
# Recommended: 15 for Colab visibility.
STATUS_UPDATE_SECONDS=15

# -----------------------------
# Model size / speed controls (safe medium profile)
# -----------------------------
# Feature cap per model; lower is faster + less memory.
# 800 is a good medium setting for first full loop.
MAX_FEATURES_PER_MODEL=800

# -----------------------------
# Walk-forward / blend runtime controls
# -----------------------------
# Keep walk-forward enabled for realistic full pipeline behavior.
WALKFORWARD_ENABLED=true

# Number of windows evaluated in walk-forward tuning.
# Lower => much faster. 2 is recommended for first end-to-end run.
WALKFORWARD_MAX_WINDOWS=2

# Number of windows used in blend tuning. Usually match WALKFORWARD_MAX_WINDOWS.
BLEND_USE_WINDOWS=2

# Global boosting rounds for normal training fits.
LGBM_NUM_BOOST_ROUND=1200

# Walk-forward/blend-window-only boosting cap.
# Lower than LGBM_NUM_BOOST_ROUND to speed up tuning stage.
WALKFORWARD_NUM_BOOST_ROUND=600

# Early stopping patience.
LGBM_EARLY_STOPPING_ROUNDS=100

# -----------------------------
# Optional quality/speed switches
# -----------------------------
# full: use whatever explicit env values you set (default)
# balanced: applies conservative speed-focused defaults for missing knobs
TRAIN_PROFILE=full

# all/medium/small from features.json (small is fastest, lower quality).
# NUMERAI_FEATURE_SET=all

# Keep enabled: code infers feature integer types from parquet schema (not filename suffix).
# v5.2 canonical files (train.parquet / validation.parquet) can still load with int8 feature dtype.
USE_INT8_PARQUET=true

# CPU is stable default in Colab; GPU for LightGBM can be unavailable depending on OpenCL.
LGBM_DEVICE=cpu

# If true, runs a tiny LightGBM CPU/GPU probe and auto-resolves LGBM_DEVICE.
# Recommended true only when validating a new Colab GPU runtime.
RUN_LGBM_GPU_PROBE=false

# -----------------------------
# Usually leave default unless experimenting
# -----------------------------
# LGBM_NUM_LEAVES=128
# LGBM_LEARNING_RATE=0.02
# LGBM_FEATURE_FRACTION=0.7
# LGBM_BAGGING_FRACTION=0.8
# LGBM_BAGGING_FREQ=1
# LGBM_MIN_DATA_IN_LEAF=1000
